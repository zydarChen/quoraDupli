{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/software/home/chenzh/software/jupyter/quoraDupli\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 工作路径改为/quoraDupli\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(os.path.join('data', '2_word2vec_tfidf.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training pairs: 355775\n",
      "Number of testing pairs: 48515\n"
     ]
    }
   ],
   "source": [
    "df = df.reindex(np.random.permutation(df.index))\n",
    "\n",
    "# set number of train and test instances\n",
    "num_train = int(df.shape[0] * 0.88)\n",
    "num_test = df.shape[0] - num_train                 \n",
    "print(\"Number of training pairs: %i\"%(num_train))\n",
    "print(\"Number of testing pairs: %i\"%(num_test))\n",
    "\n",
    "# init data data arrays\n",
    "X_train = np.zeros([num_train, 2, 300])\n",
    "X_test  = np.zeros([num_test, 2, 300])\n",
    "Y_train = np.zeros([num_train]) \n",
    "Y_test = np.zeros([num_test])\n",
    "\n",
    "# format data \n",
    "b = [a[None,:] for a in list(df['q1_feats'].values)]\n",
    "q1_feats = np.concatenate(b, axis=0)\n",
    "\n",
    "b = [a[None,:] for a in list(df['q2_feats'].values)]\n",
    "q2_feats = np.concatenate(b, axis=0)\n",
    "\n",
    "# fill data arrays with features\n",
    "X_train[:,0,:] = q1_feats[:num_train]\n",
    "X_train[:,1,:] = q2_feats[:num_train]\n",
    "Y_train = df[:num_train]['is_duplicate'].values\n",
    "            \n",
    "X_test[:,0,:] = q1_feats[num_train:]\n",
    "X_test[:,1,:] = q2_feats[num_train:]\n",
    "Y_test = df[num_train:]['is_duplicate'].values\n",
    "\n",
    "# remove useless variables\n",
    "del b\n",
    "del q1_feats\n",
    "del q2_feats\n",
    "\n",
    "# preprocess data, unit std\n",
    "X_train_norm = np.zeros_like(X_train)\n",
    "d = (np.sum(X_train[:,0,:] ** 2, 1) ** (0.5))\n",
    "X_train_norm[:,0,:] = (X_train[:,0,:].T / (d + 1e-8)).T\n",
    "d = (np.sum(X_train[:,1,:] ** 2, 1) ** (0.5))\n",
    "X_train_norm[:,1,:] = (X_train[:,1,:].T / (d + 1e-8)).T\n",
    "\n",
    "\n",
    "X_test_norm = np.zeros_like(X_test)\n",
    "d = (np.sum(X_test[:,0,:] ** 2, 1) ** (0.5))\n",
    "X_test_norm[:,0,:] = (X_test[:,0,:].T / (d + 1e-8)).T\n",
    "d = (np.sum(X_test[:,1,:] ** 2, 1) ** (0.5))\n",
    "X_test_norm[:,1,:] = (X_test[:,1,:].T / (d + 1e-8)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Lambda, merge, BatchNormalization, Activation, Input, Merge\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def cosine_distance(vests):\n",
    "    x, y = vests\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def cos_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "\n",
    "def create_base_network(input_dim):\n",
    "    '''\n",
    "    Base network for feature extraction.\n",
    "    '''\n",
    "    input = Input(shape=(input_dim, ))\n",
    "    dense1 = Dense(128)(input)\n",
    "    bn1 = BatchNormalization()(dense1)\n",
    "#     bn1 = BatchNormalization(mode=2)(dense1)\n",
    "    relu1 = Activation('relu')(bn1)\n",
    "\n",
    "    dense2 = Dense(128)(relu1)\n",
    "    bn2 = BatchNormalization()(dense2)\n",
    "#     bn2 = BatchNormalization(mode=2)(dense2)\n",
    "    res2 = merge([relu1, bn2], mode='sum')\n",
    "    relu2 = Activation('relu')(res2)    \n",
    "\n",
    "    dense3 = Dense(128)(relu2)\n",
    "    bn3 = BatchNormalization()(dense3)\n",
    "#     bn3 = BatchNormalization(mode=2)(dense3)\n",
    "    res3 = Merge(mode='sum')([relu2, bn3])\n",
    "    relu3 = Activation('relu')(res3)   \n",
    "    \n",
    "    feats = merge([relu3, relu2, relu1], mode='concat')\n",
    "    bn4 = BatchNormalization()(feats)\n",
    "#     bn4 = BatchNormalization(mode=2)(feats)\n",
    "\n",
    "    model = Model(input=input, output=bn4)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    '''\n",
    "    Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return labels[predictions.ravel() < 0.5].mean()\n",
    "\n",
    "def create_network(input_dim):\n",
    "    # network definition\n",
    "    base_network = create_base_network(input_dim)\n",
    "    \n",
    "    input_a = Input(shape=(input_dim,))\n",
    "    input_b = Input(shape=(input_dim,))\n",
    "    \n",
    "    # because we re-use the same instance `base_network`,\n",
    "    # the weights of the network\n",
    "    # will be shared across the two branches\n",
    "    processed_a = base_network(input_a)\n",
    "    processed_b = base_network(input_b)\n",
    "    \n",
    "    distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "    \n",
    "    model = Model(input=[input_a, input_b], output=distance)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/home/chenzh/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:45: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/software/home/chenzh/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:51: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/software/home/chenzh/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:54: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/software/home/chenzh/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:58: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ba..., inputs=Tensor(\"in...)`\n",
      "/software/home/chenzh/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:84: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"la..., inputs=[<tf.Tenso...)`\n",
      "/software/home/chenzh/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:12: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 5.5516 - val_loss: 0.2150\n",
      "* Accuracy on test set: 57.74%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1850 - val_loss: 0.1730\n",
      "* Accuracy on test set: 64.09%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1654 - val_loss: 0.1612\n",
      "* Accuracy on test set: 67.14%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1552 - val_loss: 0.1547\n",
      "* Accuracy on test set: 68.41%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1480 - val_loss: 0.1487\n",
      "* Accuracy on test set: 70.96%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1418 - val_loss: 0.1458\n",
      "* Accuracy on test set: 71.01%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1369 - val_loss: 0.1428\n",
      "* Accuracy on test set: 72.18%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1330 - val_loss: 0.1414\n",
      "* Accuracy on test set: 72.47%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1296 - val_loss: 0.1406\n",
      "* Accuracy on test set: 72.30%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1267 - val_loss: 0.1397\n",
      "* Accuracy on test set: 73.70%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1244 - val_loss: 0.1388\n",
      "* Accuracy on test set: 73.96%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1224 - val_loss: 0.1378\n",
      "* Accuracy on test set: 74.24%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1204 - val_loss: 0.1374\n",
      "* Accuracy on test set: 73.59%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1189 - val_loss: 0.1369\n",
      "* Accuracy on test set: 72.97%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1172 - val_loss: 0.1368\n",
      "* Accuracy on test set: 72.86%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1162 - val_loss: 0.1363\n",
      "* Accuracy on test set: 74.41%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1149 - val_loss: 0.1363\n",
      "* Accuracy on test set: 73.75%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1138 - val_loss: 0.1366\n",
      "* Accuracy on test set: 74.44%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1128 - val_loss: 0.1360\n",
      "* Accuracy on test set: 73.33%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1119 - val_loss: 0.1361\n",
      "* Accuracy on test set: 73.81%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1111 - val_loss: 0.1355\n",
      "* Accuracy on test set: 74.52%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1102 - val_loss: 0.1359\n",
      "* Accuracy on test set: 75.25%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1096 - val_loss: 0.1353\n",
      "* Accuracy on test set: 74.25%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1089 - val_loss: 0.1353\n",
      "* Accuracy on test set: 74.32%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1083 - val_loss: 0.1349\n",
      "* Accuracy on test set: 74.00%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1077 - val_loss: 0.1354\n",
      "* Accuracy on test set: 74.53%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1072 - val_loss: 0.1355\n",
      "* Accuracy on test set: 73.91%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1066 - val_loss: 0.1351\n",
      "* Accuracy on test set: 74.39%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1061 - val_loss: 0.1347\n",
      "* Accuracy on test set: 73.74%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1057 - val_loss: 0.1348\n",
      "* Accuracy on test set: 74.14%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1052 - val_loss: 0.1348\n",
      "* Accuracy on test set: 74.94%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1048 - val_loss: 0.1343\n",
      "* Accuracy on test set: 74.44%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1044 - val_loss: 0.1345\n",
      "* Accuracy on test set: 74.39%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1040 - val_loss: 0.1348\n",
      "* Accuracy on test set: 74.84%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1037 - val_loss: 0.1346\n",
      "* Accuracy on test set: 75.67%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1032 - val_loss: 0.1342\n",
      "* Accuracy on test set: 74.85%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1027 - val_loss: 0.1355\n",
      "* Accuracy on test set: 74.49%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1024 - val_loss: 0.1349\n",
      "* Accuracy on test set: 74.59%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1023 - val_loss: 0.1343\n",
      "* Accuracy on test set: 74.39%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1018 - val_loss: 0.1342\n",
      "* Accuracy on test set: 75.32%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1017 - val_loss: 0.1340\n",
      "* Accuracy on test set: 74.74%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1013 - val_loss: 0.1349\n",
      "* Accuracy on test set: 75.37%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1009 - val_loss: 0.1339\n",
      "* Accuracy on test set: 74.58%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1007 - val_loss: 0.1349\n",
      "* Accuracy on test set: 75.52%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.1004 - val_loss: 0.1353\n",
      "* Accuracy on test set: 76.01%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355775/355775 [==============================] - 20s - loss: 0.1002 - val_loss: 0.1352\n",
      "* Accuracy on test set: 75.38%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.0999 - val_loss: 0.1344\n",
      "* Accuracy on test set: 74.39%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.0998 - val_loss: 0.1343\n",
      "* Accuracy on test set: 74.91%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.0995 - val_loss: 0.1342\n",
      "* Accuracy on test set: 75.05%\n",
      "Train on 355775 samples, validate on 48515 samples\n",
      "Epoch 1/1\n",
      "355775/355775 [==============================] - 20s - loss: 0.0992 - val_loss: 0.1342\n",
      "* Accuracy on test set: 75.79%\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "net = create_network(300)\n",
    "\n",
    "# train\n",
    "#optimizer = SGD(lr=1, momentum=0.8, nesterov=True, decay=0.004)\n",
    "optimizer = Adam(lr=0.001)\n",
    "net.compile(loss=contrastive_loss, optimizer=optimizer)\n",
    "\n",
    "for epoch in range(50):\n",
    "    net.fit([X_train_norm[:,0,:], X_train_norm[:,1,:]], Y_train,\n",
    "          validation_data=([X_test_norm[:,0,:], X_test_norm[:,1,:]], Y_test),\n",
    "          batch_size=128, nb_epoch=1, shuffle=True, )\n",
    "    \n",
    "    # compute final accuracy on training and test sets\n",
    "    pred = net.predict([X_test_norm[:,0,:], X_test_norm[:,1,:]], batch_size=128)\n",
    "    te_acc = compute_accuracy(pred, Y_test)\n",
    "    \n",
    "#    print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "    print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
